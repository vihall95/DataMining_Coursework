{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cfdaeb",
   "metadata": {},
   "source": [
    "# Week 3 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65a2c7a",
   "metadata": {},
   "source": [
    "## Victoria Hall\n",
    "## DSC550\n",
    "## 12.17.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ed8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import Word\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb75afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading File\n",
    "movie_df = pd.read_csv('labeledTrainData.tsv',sep = '\\t')\n",
    "movie_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a3bed",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "#### 2. How many positive and negative reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf726c",
   "metadata": {},
   "source": [
    "Sentiment values labeled as 0 have IMBD ratings below 5, indicating a negative review. Sentiment values of 1 indicate postive reviews. Our data is balanced, as 12500 reviews are negative and 12500 is positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665bb929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding unique values\n",
    "movie_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0805cb",
   "metadata": {},
   "source": [
    "#### 3 and 4. Check the accuracy of this model. Is this model better than random guessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21d0c4",
   "metadata": {},
   "source": [
    "Our model was about 69% accurate. Assuming that with random guessing we would be 50% accurate, our model is more accurate that random guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef6b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function to get polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity\n",
    "\n",
    "#Creating new column for polarity\n",
    "movie_df[\"Polarity\"] = movie_df['review'].apply(getPolarity)\n",
    "movie_df.head(5)\n",
    "\n",
    "#Creating binary classifer for polarity\n",
    "movie_df[\"Polarity_Binary\"] = np.where(movie_df[\"Polarity\"] >= 0,1,0)\n",
    "movie_df.head(5)\n",
    "\n",
    "#Finding Accuracy\n",
    "movie_df[\"accuracy\"] = movie_df.sentiment - movie_df.Polarity_Binary\n",
    "movie_df.accuracy.value_counts()\n",
    "17131/25000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5c05c",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd627ea",
   "metadata": {},
   "source": [
    "#### Converting to lower case, removing special characters, removing stop words, and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ee447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting text to lowercase\n",
    "movie_df[\"review\"] = movie_df[\"review\"].str.lower()\n",
    "movie_df.head(5)\n",
    "\n",
    "import unicodedata\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fa577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing white space\n",
    "movie_df[\"review_strip\"] = [string.strip() for string in movie_df[\"review\"]]\n",
    "\n",
    "#Removing punctuation\n",
    "#Creating a dictionary of punc.\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                           if unicodedata.category(chr(i)).startswith(\"P\"))\n",
    "\n",
    "movie_df[\"review_nopunc\"] = [string.translate(punctuation) for string in movie_df[\"review_strip\"]]\n",
    "movie_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing. Using apply to tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "movie_df[\"tokens\"] = movie_df[\"review_nopunc\"].apply(word_tokenize)\n",
    "movie_df.head(5)\n",
    "\n",
    "#Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "movie_df[\"tokens_nostop\"] = movie_df[\"tokens\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "movie_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "movie_df[\"Stems\"] = movie_df[\"tokens_nostop\"].apply(lambda x: [porter.stem(word) for word in x])\n",
    "movie_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fb0f9",
   "metadata": {},
   "source": [
    "#### Bag of Words Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Creating the matrix\n",
    "count= CountVectorizer()\n",
    "text = np.array(movie_df.Stems.astype(str))\n",
    "Bag_of_Words = count.fit_transform(text)\n",
    "Bag_of_Words\n",
    "#Finding the dimensions.\n",
    "bagshape = Bag_of_Words.shape\n",
    "bagshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104801a1",
   "metadata": {},
   "source": [
    "#### Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Creating the matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text)\n",
    "feature_matrix\n",
    "\n",
    "#Finding the dimensions\n",
    "featshape = feature_matrix.shape\n",
    "featshape\n",
    "\n",
    "#Checking if dimensions are the same\n",
    "print(bagshape==featshape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
